;;    -> Phase 3: Experiments

  ;; an interesting experiment for the eval phase would be
  ;; allowing a binary logical operator that combined a logical
  ;; operator with a stateful logical predicate of the ast
  ;; generated. Once the tree walk functions are built this will be
  ;; very powerful.

;; Longest

;; make a longest possible match operator. this would involve a primitive
;; that would scope a token match counter. The recursive match with the
;; highest token count would be returned. This approach to longest match
;; assumes packrat optimization, and that constructing ast is a cheap
;; operation.

;; Lazy

;; is it possible to make the parser lazy instead of greedy with a
;; closure while still being top-down ?  with packrat optimization an
;; interesting algorithm for efficiently constructing a correct lazy
;; match for a sequence might be possible.

;; If such an algorithm was found enabling something like CFG
;; semantics then the parser compiler would be a much more interesting
;; beast.

;; lazy may need to be a sequence relational operator but that is quite odd.
;; can top-down work right to left ? maybe I could scan back from a sync token
;; and do the sequence matching in reverse.

;; A B C

;; A runs match. If it works it lets B take a crack at the next run. If B doesn't
;; match it goes back to A for more greed. If B does match then B becomes A and
;; C is bound as B until the sequence is exhausted.

;; Since the tokens never actually implement greed themselves this may
;; actually work. implications of recursively buried greed ?

;; 2. tracing at the primitive level, generating instrumented parser functions.

;; 3. Could tokens be emacs functions that bound the existing syntax anaylsis
;;    of a buffer ? kind of a high level data structure builder on-top of the
;;    existing function ?

;; Badly formed inputs: a way to terminate a previous match ? something like the
;; proposed super brace ? would it help with stuff like HTML parsing ?


What about a sepia interface to mod_perl ? could it work like slime ?
could it work over ssh ?

---> Ruminations <---

my own interest in Emacs development is essentially self-interest in
that I want features I consider necessary tools for development.
I believe that I can create unique tools. The scope of the tools
can be limited to things like a template, and templates that
can morph code intelligently.

Imagining the use of these tools without considering the creativity
of the end-user constrains the value of the tools to my limitations.
If I expand my thinking, my perspective of value, so that I see
my tools as a distribution of my expertise in a form that can be
used by another without aquiring my domain knowledge, it is merely
a program or feature. There is no usefulness beyond what I add to
it.

If I imagine that I can create a vehicle that others can use to
develop and effectively distribute their expertise I have created
a system vastly more powerful than a feature alone.

Could templates on a much higher level of conception be used as a way
to distribute technique, expertise, knowledge ? Could it both teach
and automate ?

Such a thing would be powerful indeed.

What if I looked at a package manger hooked up to Emacs as a deployment mechanism.
With a modern package manager you can merge multiple repositories ala paludis.
This sort of arrangement is ideal for merging Global tools such as the ones distributed
with Emacs, with "shop" tools distributed within a particular organization.

If I apply this line of thought to my template system then It comes to mind that
the templates could be managed with a system like this. The problem then becomes
how do you associate a given buffer with the templates ?

Could the various tests, debugging methods, refactor techniques, and idioms
be distributed as both knowledge and tool throughout the project through
such a system ?

could I have a directory called kung-fu, where I could move styles into
that directory, have those features autoload as part of the config ?

basically automate the hell out of that loop ?

--> interface for deploy.

one key should generate the install dependencies, run with -p. It should integrate
nicely with the existing display. create a marker for the region. Another key
should perform the install.

the search program can place the markers and give them the generic name of the
install region. The install part is orthogonal as it can simply operate within
the region defined by the markers. Both the install dependencies and the actual
installation log can go in that region.

--> old <--

* Just for Fun

  build a foreign function interface that allows parrot closures
  to be created and called from emacs by embedding parrot ( insane+ ).

  allow parrot code to callback into emacs, analyze risk of
  changing semantics,side-effects etc.

  push up syntax trees into the invisible annotations of a buffer.
  be able to sync via a function.

  is it the mythical Babel :) they will run screaming.

* glasses-mode can be used for langauges that use case-change
  as a word seperator e.g: FooBar

  A. the main part is done. I need to copy the original as well for
     diffing against.  It also needs to have version information
     encoded !!!!! I should be able to get the strings of the current
     emacs version, and then encode that. How to ensure that further
     diffs work ? possibly emit a script to perform the diff.

* use comint 'send-invisible' to dump a function into the interperter,
  for this to be really cool , it would need to copy the function by tags lookup
  automatically reformatting as necessary.

* env-tree needs to be modified to work with the env program. Simply
  executing a subshell will not work with things like eshell which I
  use on emacs, other systems like windows where the shell is not fully
  intergrated will rely on a program like env as well.

* vc stuff

  -> vc-before-checkin-hook is run right before the pop-to-buffer
     command in vc-start-entry. As long as there are no side effects
     changing the current-buffer to a read-only diff between the
     working-copy and the current version should work. No cleanup
     would be performed though :( TODO

     -> needs to get the file value for the current buffer: the working copy.

     -> diff against last checkin

     -> make the diff read-only

     -> make the current buffer the diff.

* Things needed:

   hunk recovery. The ability to scrub all the plus and minuses to
   restore the text encompassed by a hunk to it's original content.


-> quit-merge.el <-

first I need to make the problem more clear and visualize it correctly as phase 1:

phase 2 will be a insanely awesome scheme program, but phase 1 will use quilt as is.


